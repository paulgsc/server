# ===================================
# Transcriber Service Configuration
# ===================================

# External SSD mount point for Whisper models
# This should point to your external hard drive
WHISPER_MODELS_PATH=/mnt/external-ssd/whisper-models

# Model selection (inside the container, this will be /models/MODEL_NAME)
# Recommended for 4-core CPU: ggml-base.en-q5_1.bin
WHISPER_MODEL=/models/ggml-base.en-q5_1.bin

# CPU Usage Settings
# -------------------
# IMPORTANT: Balance these for your 4-core CPU

# Number of threads for Whisper inference
# 2 threads = ~50% CPU usage (leaves room for other services)
# 3 threads = ~75% CPU usage
# 4 threads = 100% CPU usage (not recommended with other services)
WHISPER_THREADS=2

# Buffer duration in seconds
# Higher = less frequent transcriptions = lower CPU usage
# Lower = more frequent transcriptions = higher accuracy but more CPU
# Recommended: 3-4 seconds for CPU efficiency
BUFFER_DURATION=3

# NATS Configuration
# ------------------
NATS_URL=nats://nats:4222

# OpenTelemetry Configuration
# ---------------------------
OTEL_EXPORTER_OTLP_ENDPOINT=http://otel-collector:4317
OTEL_SERVICE_NAME=transcriber

# Logging
# -------
# Options: error, warn, info, debug, trace
# Use 'info' in production, 'debug' for troubleshooting
RUST_LOG=info,transcriber=info

# ===================================
# Model Performance Profiles
# ===================================

# Profile 1: Minimal CPU Usage (tiny model)
# ------------------------------------------
# WHISPER_MODEL=/models/ggml-tiny.en-q5_1.bin
# WHISPER_THREADS=1
# BUFFER_DURATION=5
# CPU Usage: ~15-20%
# Latency: Very low
# Accuracy: Lower (good for simple speech)

# Profile 2: Balanced (base model) ‚≠ê RECOMMENDED
# -----------------------------------------------
# WHISPER_MODEL=/models/ggml-base.en-q5_1.bin
# WHISPER_THREADS=2
# BUFFER_DURATION=3
# CPU Usage: ~30-40%
# Latency: Low
# Accuracy: Good (suitable for most use cases)

# Profile 3: Higher Accuracy (small model)
# -----------------------------------------
# WHISPER_MODEL=/models/ggml-small.en-q5_1.bin
# WHISPER_THREADS=3
# BUFFER_DURATION=4
# CPU Usage: ~60-70%
# Latency: Medium
# Accuracy: Better (technical terms, accents)

# Profile 4: Maximum Accuracy (medium model) - NOT RECOMMENDED FOR 4-CORE CPU
# ---------------------------------------------------------------------------
# WHISPER_MODEL=/models/ggml-medium.en-q5_1.bin
# WHISPER_THREADS=3
# BUFFER_DURATION=5
# CPU Usage: ~80-100%
# Latency: High
# Accuracy: Best (but will impact other services)

# ===================================
# Docker Resource Limits
# ===================================
# These are set in docker-compose.yml
# Transcriber container is limited to:
# - 2.0 CPUs max (50% of your 4-core system)
# - 1GB memory max
# - Lower scheduling priority (cpu_shares: 512)
# - OOM kill priority (oom_score_adj: 500)

# ===================================
# External SSD Setup Notes
# ===================================
# 1. Mount your external SSD:
#    sudo mount /dev/sdX1 /mnt/external-ssd
#
# 2. Add to /etc/fstab for auto-mount:
#    UUID=xxxx /mnt/external-ssd ext4 defaults,nofail 0 2
#
# 3. Create models directory:
#    mkdir -p /mnt/external-ssd/whisper-models
#
# 4. Download model:
#    ./download-models.sh
#
# 5. Update WHISPER_MODELS_PATH above

# ===================================
# Performance Tuning Tips
# ===================================
# - Start with Profile 2 (balanced)
# - Monitor CPU usage: docker stats transcriber
# - If CPU usage too high:
#   * Decrease WHISPER_THREADS
#   * Increase BUFFER_DURATION
#   * Use smaller model (tiny)
# - If transcription quality poor:
#   * Use larger model (small)
#   * Decrease BUFFER_DURATION
#   * Increase WHISPER_THREADS (if CPU available)
# - If other services struggling:
#   * Lower transcriber priority further in docker-compose.yml
#   * Consider running transcriber on-demand only
